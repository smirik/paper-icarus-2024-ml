{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy pandas matplotlib scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator, AutoMinorLocator\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"Helvetica\"\n",
    "})\n",
    "\n",
    "fontSize = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/kNN_parameters_grid.csv')\n",
    "df = df[(df['P']==1) & (df['Weights'] == 'distance')].sort_values(by='N_neighbors')\n",
    "x = df['N_neighbors']\n",
    "y1 = df['Recall']\n",
    "y2 = df['Precision']\n",
    "y3 = df['F1 score']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(10))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.05))\n",
    "\n",
    "plt.plot(x, y1, c='#1f77b4', label='Recall', marker='o', linestyle='-', linewidth=1, markersize=2)\n",
    "plt.plot(x, y2, c='#7f7f7f', label='Precision', marker='^', linestyle='-', linewidth=1, markersize=2)\n",
    "plt.plot(x, y3, c='#d62728', label='$F_1$ score', marker='s', linestyle='-', linewidth=1, markersize=2)\n",
    "\n",
    "plt.xticks(range(0, 101, 20), fontsize=18)\n",
    "plt.yticks([i/10 for i in range(11)], fontsize=18)\n",
    "\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.3)\n",
    "\n",
    "plt.xlabel('k, Number of nearest neighbours', fontsize=18)\n",
    "plt.ylabel('Metrics', fontsize=18)\n",
    "plt.title('Metrics vs GRID k ($p=1$, with $n$ only)', fontsize=18)\n",
    "plt.legend(fontsize=16)\n",
    "\n",
    "plt.ylim(0.8, 1.01)\n",
    "plt.xlim(3, 99)\n",
    "\n",
    "plt.savefig('output/kNN_vs_k2.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/kNN_features.csv')\n",
    "\n",
    "df['k'] = df['Meth. & Params'].str.extract('k=(\\d+)', expand=False).astype(int)\n",
    "df['p'] = df['Meth. & Params'].str.extract('p=(\\d+)', expand=False).astype(int)\n",
    "df['w'] = df['Meth. & Params'].str.extract('w=(\\d+)', expand=False).astype(int)\n",
    "\n",
    "df_selected = df[(df['Train NR'] == 16280) & (df['Train R'] == 50)]\n",
    "\n",
    "selected_columns = ['k', 'p', 'w', 'Features', 'TP', 'FP', 'TN', 'FN', 'Acc.', 'Prec.', 'Rec.', 'F1']\n",
    "df_selected = df_selected[selected_columns]\n",
    "df_selected = df_selected.sort_values(by=['k', 'p', 'w', 'F1', 'Rec.', 'Features'], ascending=[True, True, True, False, False, True])\n",
    "\n",
    "df_selected.groupby(['k', 'p', 'w']).head(1)\n",
    "\n",
    "\n",
    "# df_selected.head(10)\n",
    "# df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected = df_selected[(df_selected['k'] == 3) & (df_selected['p'] == 1) & (df_selected['w'] == 1)]\n",
    "df_latex = df_selected.drop(['k', 'p', 'w'], axis=1)\n",
    "\n",
    "latex_table = df_latex.to_latex(index=False)\n",
    "# latex_table = pd.DataFrame(df_selected).style.to_latex(index=False)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/kNN_parameters.csv')\n",
    "\n",
    "df['k'] = df['Meth. & Params'].str.extract('k=(\\d+)', expand=False).astype(int)\n",
    "df['p'] = df['Meth. & Params'].str.extract('p=(-?\\d+)', expand=False).astype(int)\n",
    "df['w'] = df['Meth. & Params'].str.extract('w=(\\d+)', expand=False).astype(int)\n",
    "\n",
    "selected_columns = ['k', 'p', 'w', 'Features', 'TP', 'FP', 'TN', 'FN', 'Acc.', 'Prec.', 'Rec.', 'F1']\n",
    "df_selected = df[selected_columns]\n",
    "\n",
    "df_selected.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_selected[(df_selected['Features'] == 'n') & (df_selected['p'] == 1) & (df_selected['w'] == 1)]\n",
    "\n",
    "x = df['k']\n",
    "y1 = df['Rec.']\n",
    "y2 = df['Prec.']\n",
    "y3 = df['F1']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(10))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.05))\n",
    "\n",
    "plt.plot(x, y1, c='#1f77b4', label='Recall', marker='o', linestyle='-', linewidth=1, markersize=2)\n",
    "plt.plot(x, y2, c='#7f7f7f', label='Precision', marker='^', linestyle='-', linewidth=1, markersize=2)\n",
    "plt.plot(x, y3, c='#d62728', label='$F_1$ score', marker='s', linestyle='-', linewidth=1, markersize=2)\n",
    "\n",
    "plt.xticks(range(0, 101, 20), fontsize=18)\n",
    "plt.yticks([i/10 for i in range(11)], fontsize=18)\n",
    "\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.3)\n",
    "\n",
    "plt.xlabel('k, Number of nearest neighbours', fontsize=18)\n",
    "plt.ylabel('Metrics', fontsize=18)\n",
    "plt.title('Metrics vs the number of neighbours ($p=1$, $n$ only)', fontsize=18)\n",
    "plt.legend(fontsize=16)\n",
    "\n",
    "plt.ylim(0.5, 1.01)\n",
    "plt.xlim(3, 99)\n",
    "\n",
    "plt.savefig('output/kNN_vs_k.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n = df_selected[(df_selected['Features'] == 'n') & (df_selected['p'] == 1) & (df_selected['w'] == 1)]\n",
    "df_a = df_selected[(df_selected['Features'] == 'a') & (df_selected['p'] == 1) & (df_selected['w'] == 1)]\n",
    "df_a_n = df_selected[(df_selected['Features'] == 'a, n') & (df_selected['p'] == 1) & (df_selected['w'] == 1)]\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 8), sharey=False, sharex=True)\n",
    "\n",
    "i=0\n",
    "dfs = [df_n, df_a, df_a_n]\n",
    "labels = ['n', 'a', 'a, n']\n",
    "for ax in axs:\n",
    "    ax.plot(dfs[i]['k'], dfs[i]['Rec.'], label='Recall', c='#1f77b4', marker='o', linestyle='-', linewidth=1, markersize=2)\n",
    "    ax.plot(dfs[i]['k'], dfs[i]['Prec.'], label='Precision', c='#7f7f7f', marker='^', linestyle='-', linewidth=1, markersize=2)\n",
    "    ax.plot(dfs[i]['k'], dfs[i]['F1'], label='$F_1$ score', c='#d62728', marker='s', linestyle='-', linewidth=1, markersize=2)\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.3)\n",
    "    ax.set_ylabel('Metrics', fontsize=fontSize)\n",
    "    if i==2:\n",
    "        ax.set_xlabel('k, the number of neighbours', fontsize=fontSize)\n",
    "    ax.set_title(f\"Features: {labels[i]}\", fontsize=fontSize)\n",
    "    ax.set_ylim(0.5, 1.01)\n",
    "    ax.set_xlim(3, 99)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=fontSize)\n",
    "    ax.legend().remove()\n",
    "    i+=1\n",
    "\n",
    "plt.setp(axs, xticks=range(10, 100, 10), yticks=[0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "plt.subplots_adjust(wspace=0.0)  # Remove horizontal spacing between subplots\n",
    "\n",
    "fig.suptitle('Metrics vs the number of neigbours, $p=1$', fontsize=fontSize+5, y=1.1)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 1.05), ncols=3, fontsize=fontSize)\n",
    "plt.subplots_adjust(wspace=0.0, hspace=0.0)  # Remove horizontal spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('output/kNN_parameters_all.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/kNN_initial_data.csv')\n",
    "\n",
    "df['k'] = df['Meth. & Params'].str.extract('k=(\\d+)', expand=False).astype(int)\n",
    "df['p'] = df['Meth. & Params'].str.extract('p=(-?\\d+)', expand=False).astype(int)\n",
    "\n",
    "selected_columns = ['Train R', 'k', 'p', 'Features', 'TP', 'FP', 'TN', 'FN', 'Acc.', 'Prec.', 'Rec.', 'F1']\n",
    "df_selected = df[selected_columns]\n",
    "\n",
    "df_selected.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3_results = df_selected[(df_selected['p'] == 1)].groupby(['Features', 'p', 'k']).apply(lambda x: x.nlargest(3, 'F1')).reset_index(drop=True)\n",
    "top_3_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_latex = top_3_results.drop(['p'], axis=1)\n",
    "latex_table = df_latex.to_latex(index=False)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_k3 = df_selected[(df_selected['Features'] == 'n') & (df_selected['p'] == 1) & (df_selected['k'] == 3)]\n",
    "df_k3d = df_selected[(df_selected['Features'] == 'a, n') & (df_selected['p'] == 1) & (df_selected['k'] == 3)]\n",
    "df_k16 = df_selected[(df_selected['Features'] == 'a, n') & (df_selected['p'] == 1) & (df_selected['k'] == 16)]\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 8), sharey=False, sharex=True)\n",
    "\n",
    "i=0\n",
    "dfs = [df_k16, df_k3, df_k3d]\n",
    "labels = ['Features: $a$, $n$; $k=16$', 'Features: $n$; $k=3$', 'Features: $a$, $n$; $k=3$']\n",
    "for ax in axs:\n",
    "    ax.plot(dfs[i]['Train R'], dfs[i]['Rec.'], label='Recall', c='#1f77b4', marker='o', linestyle='-', linewidth=1, markersize=2)\n",
    "    ax.plot(dfs[i]['Train R'], dfs[i]['Prec.'], label='Precision', c='#7f7f7f', marker='^', linestyle='-', linewidth=1, markersize=2)\n",
    "    ax.plot(dfs[i]['Train R'], dfs[i]['F1'], label='$F_1$ score', c='#d62728', marker='s', linestyle='-', linewidth=1, markersize=2)\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.3)\n",
    "    ax.set_ylabel('Metrics', fontsize=fontSize)\n",
    "    if i==2:\n",
    "        ax.set_xlabel('n, the number of resonant asteroids in the training set', fontsize=fontSize)\n",
    "    ax.set_title(f\"{labels[i]}\", fontsize=fontSize)\n",
    "    ax.set_ylim(0.5, 1.01)\n",
    "    ax.set_xlim(3, 99)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=fontSize)\n",
    "    ax.legend().remove()\n",
    "    i+=1\n",
    "\n",
    "plt.setp(axs, xticks=range(10, 100, 10), yticks=[0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "plt.subplots_adjust(wspace=0.0)  # Remove horizontal spacing between subplots\n",
    "\n",
    "fig.suptitle('Metrics vs the size of the training set', fontsize=fontSize+5, y=1.1)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 1.05), ncols=3, fontsize=fontSize)\n",
    "plt.subplots_adjust(wspace=0.0, hspace=0.0)  # Remove horizontal spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('output/kNN_initial_data.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/DT_parameters.csv')\n",
    "\n",
    "df['d'] = df['Meth. & Params'].str.extract('d=(\\d+)', expand=False).astype(int)\n",
    "df['p'] = df['Meth. & Params'].str.extract('p=(-?\\d+)', expand=False).astype(int)\n",
    "df['w'] = df['Meth. & Params'].str.extract('w=(\\d+)', expand=False).astype(int)\n",
    "df['s'] = df['Meth. & Params'].str.extract('s=(\\d+)', expand=False).astype(int)\n",
    "df['l'] = df['Meth. & Params'].str.extract('l=(\\d+)', expand=False).astype(int)\n",
    "df['f'] = df['Meth. & Params'].str.extract('f=([a-zA-Z0-9]+)', expand=False)\n",
    "\n",
    "selected_columns = ['Train R', 'd', 'p', 'w', 's', 'l', 'f', 'Features', 'TP', 'FP', 'TN', 'FN', 'Acc.', 'Prec.', 'Rec.', 'F1']\n",
    "df = df[selected_columns]\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['F1', 'Rec.', 'Prec.'], ascending=[False, False, False]).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "# Replace values in column 'f'\n",
    "# df2['f'] = df2['f'].replace({'None': 0, 'sqrt': 1, 'log2': 2})\n",
    "# feature_mapping = {feature: i for i, feature in enumerate(df2['Features'].unique())}\n",
    "# df2['Features'] = df2['Features'].replace(feature_mapping)\n",
    "\n",
    "correlations = df2[['Rec.', 'd', 'w', 's', 'l']].corr(method='spearman', numeric_only=False)\n",
    "correlations = correlations.round(4)\n",
    "print(correlations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Assuming `df` is your DataFrame with 'impurity' and 'F1_score' columns\n",
    "metric = 'F1'\n",
    "fvalue, pvalue = stats.f_oneway(df[df['w'] == 0][metric],\n",
    "                                df[df['w'] == 1][metric])\n",
    "print(f\"weights: F-Value: {fvalue}, P-Value: {pvalue.round(4)}\")\n",
    "\n",
    "fvalue, pvalue = stats.f_oneway(df[df['p'] == 1][metric],\n",
    "                                df[df['p'] == 2][metric],\n",
    "                                df[df['p'] == 3][metric])\n",
    "print(f\"impurity: F-Value: {fvalue}, P-Value: {pvalue}\")\n",
    "fvalue, pvalue = stats.f_oneway(df[df['f'] == 'log2'][metric],\n",
    "                                df[df['f'] == 'None'][metric],\n",
    "                                df[df['f'] == 'sqrt'][metric])\n",
    "print(f\"max_features: F-Value: {fvalue}, P-Value: {pvalue.round(4)}\")\n",
    "fvalue, pvalue = stats.f_oneway(df[df['Features'] == 'a'][metric],\n",
    "                                df[df['Features'] == 'a, n, sinI'][metric],\n",
    "                                df[df['Features'] == 'a, e'][metric],\n",
    "                                df[df['Features'] == 'a, sinI'][metric])\n",
    "print(f\"Features: F-Value: {fvalue}, P-Value: {pvalue.round(4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_values = df.groupby(['p']).mean()\n",
    "average_values = average_values[['Rec.', 'Prec.', 'F1']]\n",
    "average_values = average_values.round(4)\n",
    "average_values.sort_values(by='F1', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_values = df.groupby(['w', 'p', 'Features', 'f']).mean()\n",
    "average_values = average_values[['Rec.', 'Prec.', 'F1']]\n",
    "average_values = average_values.round(4)\n",
    "# average_values.sort_values(by='F1', ascending=False).to_csv('res.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.sort_values(by=['F1', 'Rec.', 'Prec.'], ascending=[False, False, False]).head(10).to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df['F1'] > 0.910].sort_values(by=['d', 'p', 'w', 's', 'l', 'Features', 'f'])\n",
    "# filtered_df.to_csv('filtered_records.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['p', 'w', 's', 'l', 'f']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['w'] == 0) & (df['s'] == 6) & (df['l'] == 5) & (df['Features'] == 'a, n, sinI') & (df['d'] == 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ordered = df.sort_values(by='F1', ascending=False).head(500)\n",
    "grouped_df = df_ordered.groupby('Features').size()\n",
    "grouped_df = grouped_df.sort_values(ascending=False)\n",
    "print(grouped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe\n",
    "df_filtered = df_ordered[df_ordered['Features'] == 'sinI, n']\n",
    "# Iterate over the rows of the filtered dataframe\n",
    "for index, row in df_filtered.iterrows():\n",
    "    # Find all rows in the original dataframe that have the same values of 'd', 'p', 'w', 's', 'l', and 'f'\n",
    "    matching_rows = df_ordered[(df_ordered['d'] == row['d']) & (df_ordered['p'] == row['p']) & (df_ordered['w'] == row['w']) & (df_ordered['s'] == row['s']) & (df_ordered['l'] == row['l']) & (df_ordered['f'] == row['f'])]\n",
    "    # Print the row from the filtered dataframe\n",
    "    print(row.to_dict())\n",
    "    # Print the matching rows\n",
    "    print(matching_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/DT_parameters_vs_d.csv')\n",
    "\n",
    "df['d'] = df['Meth. & Params'].str.extract('d=([a-zA-Z0-9]+)', expand=False).replace('None', -1).astype(int)\n",
    "df['s'] = df['Meth. & Params'].str.extract('s=(\\d+)', expand=False).astype(int)\n",
    "df['f'] = df['Meth. & Params'].str.extract('f=([a-zA-Z0-9]+)', expand=False)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[(df['Features'] == 'a, n, sinI') & (df['d'] == -1) & (df['f'] == 'sqrt')]\n",
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[(df['Features'] == 'a, n, sinI') & (df['d'] == -1) & (df['f'] == 'sqrt')]\n",
    "\n",
    "x = df2['s']\n",
    "y1 = df2['Rec.']\n",
    "y2 = df2['Prec.']\n",
    "y3 = df2['F1']\n",
    "\n",
    "fontSize = 24\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(1))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.05))\n",
    "\n",
    "plt.plot(x, y1, c='#1f77b4', label='Recall', marker='o', linestyle='-', linewidth=1, markersize=2)\n",
    "plt.plot(x, y2, c='#7f7f7f', label='Precision', marker='^', linestyle='-', linewidth=1, markersize=2)\n",
    "plt.plot(x, y3, c='#d62728', label='$F_1$ score', marker='s', linestyle='-', linewidth=1, markersize=2)\n",
    "\n",
    "plt.xticks(range(0, 24, 5), fontsize=fontSize)\n",
    "plt.yticks([i/10 for i in range(11)], fontsize=fontSize)\n",
    "\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.3)\n",
    "\n",
    "plt.xlabel('s, The minimum number of samples to split', fontsize=fontSize)\n",
    "plt.ylabel('Metrics', fontsize=fontSize)\n",
    "plt.title('Metrics vs s ($d=-1$, $\\{a, n, \\sin{I}\\}$, $f=$ sqrt)', fontsize=fontSize)\n",
    "plt.legend(fontsize=fontSize-4)\n",
    "\n",
    "plt.ylim(0.7, 1.01)\n",
    "plt.xlim(2, 20)\n",
    "\n",
    "plt.savefig('output/DT_vs_s.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[(df['Features'] == 'a, n, sinI') & (df['s'] == 3) & (df['f'] == 'sqrt')]\n",
    "\n",
    "x = df2['d']\n",
    "y1 = df2['Rec.']\n",
    "y2 = df2['Prec.']\n",
    "y3 = df2['F1']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(10))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.05))\n",
    "\n",
    "plt.plot(x, y1, c='#1f77b4', label='Recall', marker='o', linestyle='-', linewidth=1, markersize=2)\n",
    "plt.plot(x, y2, c='#7f7f7f', label='Precision', marker='^', linestyle='-', linewidth=1, markersize=2)\n",
    "plt.plot(x, y3, c='#d62728', label='$F_1$ score', marker='s', linestyle='-', linewidth=1, markersize=2)\n",
    "\n",
    "plt.xticks(range(0, 101, 20), fontsize=fontSize)\n",
    "plt.yticks([i/10 for i in range(11)], fontsize=fontSize)\n",
    "\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.3)\n",
    "\n",
    "plt.xlabel('d, The maximum depth', fontsize=fontSize)\n",
    "plt.ylabel('Metrics', fontsize=fontSize)\n",
    "plt.title('Metrics vs d ($s=3$, $\\{a, n, \\sin{I}\\}$, $f=$ sqrt)', fontsize=fontSize)\n",
    "plt.legend(fontsize=fontSize-4)\n",
    "\n",
    "plt.ylim(0.9, 1.01)\n",
    "plt.xlim(2, 100)\n",
    "\n",
    "plt.savefig('output/DT_vs_d_s3.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/DT_initial_data.csv')\n",
    "df['s'] = df['Meth. & Params'].str.extract('s=(\\d+)', expand=False).astype(int)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[(df['Features'] == 'a, n, sinI') & (df['s'] == 3)].sort_values(by='Train R')\n",
    "\n",
    "fontSize = 20\n",
    "\n",
    "x = df2['Train R']\n",
    "y1 = df2['Rec.']\n",
    "y2 = df2['Prec.']\n",
    "y3 = df2['F1']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(10))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.05))\n",
    "\n",
    "plt.plot(x, y1, c='#1f77b4', label='Recall', marker='o', linestyle='-', linewidth=1, markersize=2)\n",
    "plt.plot(x, y2, c='#7f7f7f', label='Precision', marker='^', linestyle='-', linewidth=1, markersize=2)\n",
    "plt.plot(x, y3, c='#d62728', label='$F_1$ score', marker='s', linestyle='-', linewidth=1, markersize=2)\n",
    "\n",
    "plt.xticks(range(0, 101, 20), fontsize=fontSize)\n",
    "plt.yticks([i/10 for i in range(11)], fontsize=fontSize)\n",
    "\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.3)\n",
    "\n",
    "plt.xlabel('n, The number of resonant asteroids in the training set', fontsize=fontSize)\n",
    "plt.ylabel('Metrics', fontsize=fontSize)\n",
    "plt.title('Metrics vs n ($s=3$, $\\{a, n, \\sin{I}\\}$, $f=$ sqrt)', fontsize=fontSize)\n",
    "plt.legend(fontsize=fontSize-4)\n",
    "\n",
    "plt.ylim(0.65, 1.01)\n",
    "plt.xlim(2, 100)\n",
    "\n",
    "plt.savefig('output/DT_vs_n_s3.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('data/DT_initial_data_100.csv').sort_values(by='Train R')\n",
    "\n",
    "x = df2['Train R']\n",
    "y1 = df2['Rec.']\n",
    "y2 = df2['Prec.']\n",
    "y3 = df2['F1']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(10))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.05))\n",
    "\n",
    "plt.plot(x, y1, c='#1f77b4', label='Recall', marker='o', linestyle='-', linewidth=1, markersize=2)\n",
    "plt.plot(x, y2, c='#7f7f7f', label='Precision', marker='^', linestyle='-', linewidth=1, markersize=2)\n",
    "plt.plot(x, y3, c='#d62728', label='$F_1$ score', marker='s', linestyle='-', linewidth=1, markersize=2)\n",
    "\n",
    "plt.xticks(range(0, 101, 20), fontsize=fontSize)\n",
    "plt.yticks([i/10 for i in range(11)], fontsize=fontSize)\n",
    "\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.3)\n",
    "\n",
    "plt.xlabel('n, The number of resonant asteroids in the training set', fontsize=fontSize)\n",
    "plt.ylabel('Metrics', fontsize=fontSize)\n",
    "plt.title('Metrics vs the size of the training set (increased test set)', fontsize=fontSize)\n",
    "plt.legend(fontsize=fontSize-4)\n",
    "\n",
    "plt.ylim(0.65, 1.01)\n",
    "plt.xlim(2, 100)\n",
    "\n",
    "plt.savefig('output/DT_vs_n_100000.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/GB_grid_vs_s100.csv')\n",
    "df['Max_depth'] = df['Max_depth'].fillna(0).astype(int)\n",
    "df.sort_values(by='F1 score', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = df[(df['Features'] == 'a, sinI') & (df['Learning_rate'] == 0.20) & (df['Loss'] == 'exponential') & (df['Max_features'] == 'sqrt') & (df['Min_samples_split'] == 9) & (df['N_estimators'] == 95)]\n",
    "# df2 = df[(df['Features'] == 'a, e, n') & (df['Learning_rate'] == 0.15) & (df['Loss'] == 'exponential') & (df['Max_features'] == 'sqrt') & (df['Min_samples_split'] == 9) & (df['N_estimators'] == 95)]\n",
    "# df2 = df[(df['Features'] == 'a, e') & (df['Learning_rate'] == 0.20) & (df['Loss'] == 'exponential') & (df['Max_features'] == 'sqrt') & (df['Max_depth'] == 8) & (df['N_estimators'] == 95)]\n",
    "# df2 = df[(df['Features'] == 'a, sinI') & (df['Learning_rate'] == 0.20) & (df['Loss'] == 'exponential') & (df['Max_features'] == 'sqrt') & (df['Max_depth'] == 8) & (df['N_estimators'] == 95)]\n",
    "df2 = df[(df['Features'] == 'a, e, n, sinI') & (df['Learning_rate'] == 0.10) & (df['Loss'] == 'exponential') & (df['Max_features'] == 'sqrt') & (df['Max_depth'] == 6) & (df['N_estimators'] == 55)]\n",
    "df2 = df2.sort_values(by='Min_samples_split')\n",
    "\n",
    "x = df2['Min_samples_split']\n",
    "y1 = df2['Recall']\n",
    "y2 = df2['Precision']\n",
    "y3 = df2['F1 score']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(10))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.05))\n",
    "\n",
    "plt.plot(x, y1, c='#1f77b4', label='Recall', marker='o', linestyle='-', linewidth=1, markersize=2)\n",
    "plt.plot(x, y2, c='#7f7f7f', label='Precision', marker='^', linestyle='-', linewidth=1, markersize=2)\n",
    "plt.plot(x, y3, c='#d62728', label='$F_1$ score', marker='s', linestyle='-', linewidth=1, markersize=2)\n",
    "\n",
    "plt.xticks(range(0, 101, 20), fontsize=fontSize)\n",
    "plt.yticks([i/10 for i in range(11)], fontsize=fontSize)\n",
    "\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.3)\n",
    "\n",
    "plt.xlabel('s, the minimum number of samples required to split a node', fontsize=fontSize)\n",
    "plt.ylabel('Metrics', fontsize=fontSize)\n",
    "plt.title('Metrics vs s ($d=8$, $\\{a, e, n, \\sin{I}\\}$)', fontsize=fontSize)\n",
    "plt.legend(fontsize=fontSize-4)\n",
    "\n",
    "plt.ylim(0.9, 1.01)\n",
    "plt.xlim(0, 100)\n",
    "\n",
    "plt.savefig('output/GB_vs_s1.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [\n",
    "    df[(df['Features'] == 'a, sinI') & (df['Learning_rate'] == 0.10) & (df['Loss'] == 'exponential') & (df['Max_features'] == 'sqrt') & (df['Max_depth'] == 0) & (df['N_estimators'] == 55)].sort_values(by='Min_samples_split'),\n",
    "    df[(df['Features'] == 'a, e, n') & (df['Learning_rate'] == 0.10) & (df['Loss'] == 'exponential') & (df['Max_features'] == 'sqrt') & (df['Max_depth'] == 6) & (df['N_estimators'] == 55)].sort_values(by='Min_samples_split'),\n",
    "    df[(df['Features'] == 'a, e, n') & (df['Learning_rate'] == 0.10) & (df['Loss'] == 'exponential') & (df['Max_features'] == 'sqrt') & (df['Max_depth'] == 6) & (df['N_estimators'] == 95)].sort_values(by='Min_samples_split'),\n",
    "    df[(df['Features'] == 'a, e, n') & (df['Learning_rate'] == 0.10) & (df['Loss'] == 'exponential') & (df['Max_features'] == 'sqrt') & (df['Max_depth'] == 0) & (df['N_estimators'] == 95)].sort_values(by='Min_samples_split'),\n",
    "]\n",
    "\n",
    "fontSize=18\n",
    "\n",
    "fig, axs = plt.subplots(4, 1, figsize=(10, 8), sharey=False, sharex=True)\n",
    "\n",
    "i=0\n",
    "labels = ['Features: $a$, $\\sin{I}$; $n=55$; $d=0$', 'Features: $a$, $e$, $n$; $n=55$; $d=6$', 'Features: $a$, $e$, $n$; $n=55$; $d=6$', 'Features: $a$, $e$, $n$; $n=95$; $d=0$']\n",
    "for ax in axs:\n",
    "    ax.plot(dfs[i]['Min_samples_split'], dfs[i]['Recall'], label='Recall', c='#1f77b4', marker='o', linestyle='-', linewidth=1, markersize=2)\n",
    "    ax.plot(dfs[i]['Min_samples_split'], dfs[i]['Precision'], label='Precision', c='#7f7f7f', marker='^', linestyle='-', linewidth=1, markersize=2)\n",
    "    ax.plot(dfs[i]['Min_samples_split'], dfs[i]['F1 score'], label='$F_1$ score', c='#d62728', marker='s', linestyle='-', linewidth=1, markersize=2)\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.3)\n",
    "    ax.set_ylabel('Metrics', fontsize=fontSize)\n",
    "    if i==3:\n",
    "        ax.set_xlabel('s, the minimum number of samples required to split a node', fontsize=fontSize)\n",
    "    ax.set_title(f\"{labels[i]}\", fontsize=fontSize)\n",
    "    ax.set_ylim(0.9, 1.01)\n",
    "    ax.set_xlim(2, 100)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=fontSize)\n",
    "    ax.legend().remove()\n",
    "    i+=1\n",
    "\n",
    "plt.setp(axs, xticks=range(10, 100, 10), yticks=[0.90, 0.95, 1.00])\n",
    "plt.subplots_adjust(wspace=0.0)  # Remove horizontal spacing between subplots\n",
    "\n",
    "fig.suptitle('Metrics vs s', fontsize=fontSize+5, y=1.1)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 1.05), ncols=3, fontsize=fontSize)\n",
    "plt.subplots_adjust(wspace=0.0, hspace=0.0)  # Remove horizontal spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('output/GB_vs_s.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in dfs:\n",
    "    print(elem.sort_values(by='F1 score', ascending=False).head(60)[['Min_samples_split', 'Recall', 'Precision', 'F1 score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/GB_grid_vs_lr30.csv')\n",
    "df['Max_depth'] = df['Max_depth'].fillna(0).astype(int)\n",
    "df.sort_values(by='F1 score', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [\n",
    "    df[(df['Features'] == 'a, sinI') & (df['Min_samples_split'] == 7) & (df['Loss'] == 'exponential') & (df['Max_features'] == 'sqrt') & (df['Max_depth'] == 0) & (df['N_estimators'] == 55)].sort_values(by='Learning_rate'),\n",
    "    df[(df['Features'] == 'a, e, n') & (df['Min_samples_split'] == 7) & (df['Loss'] == 'exponential') & (df['Max_features'] == 'sqrt') & (df['Max_depth'] == 6) & (df['N_estimators'] == 55)].sort_values(by='Learning_rate'),\n",
    "    df[(df['Features'] == 'a, e, n') & (df['Min_samples_split'] == 10) & (df['Loss'] == 'exponential') & (df['Max_features'] == 'sqrt') & (df['Max_depth'] == 6) & (df['N_estimators'] == 55)].sort_values(by='Learning_rate'),\n",
    "    df[(df['Features'] == 'a, e, n') & (df['Min_samples_split'] == 7) & (df['Loss'] == 'exponential') & (df['Max_features'] == 'sqrt') & (df['Max_depth'] == 0) & (df['N_estimators'] == 95)].sort_values(by='Learning_rate'),\n",
    "]\n",
    "\n",
    "fontSize=18\n",
    "\n",
    "fig, axs = plt.subplots(4, 1, figsize=(10, 8), sharey=False, sharex=True)\n",
    "\n",
    "i=0\n",
    "labels = ['Features: $a$, $\\sin{I}$; $n=55$; $d=0$', 'Features: $a$, $e$, $n$; $n=55$; $d=6$', 'Features: $a$, $e$, $n$; $n=55$; $d=6$', 'Features: $a$, $e$, $n$; $n=95$; $d=0$']\n",
    "for ax in axs:\n",
    "    ax.plot(dfs[i]['Learning_rate'], dfs[i]['Recall'], label='Recall', c='#1f77b4', marker='o', linestyle='-', linewidth=1, markersize=2)\n",
    "    ax.plot(dfs[i]['Learning_rate'], dfs[i]['Precision'], label='Precision', c='#7f7f7f', marker='^', linestyle='-', linewidth=1, markersize=2)\n",
    "    ax.plot(dfs[i]['Learning_rate'], dfs[i]['F1 score'], label='$F_1$ score', c='#d62728', marker='s', linestyle='-', linewidth=1, markersize=2)\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.3)\n",
    "    ax.set_ylabel('Metrics', fontsize=fontSize)\n",
    "    if i==3:\n",
    "        ax.set_xlabel('lr, learning rate', fontsize=fontSize)\n",
    "    ax.set_title(f\"{labels[i]}\", fontsize=fontSize)\n",
    "    ax.set_ylim(0.0, 1.01)\n",
    "    ax.set_xlim(0.01, 0.30)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=fontSize)\n",
    "    ax.legend().remove()\n",
    "    i+=1\n",
    "\n",
    "plt.setp(axs, xticks=[(i+1)/100 for i in range(4, 31, 5)], yticks=[0.0, 0.5, 1.00])\n",
    "plt.subplots_adjust(wspace=0.0)  # Remove horizontal spacing between subplots\n",
    "\n",
    "fig.suptitle('Metrics vs learning rate', fontsize=fontSize+5, y=1.1)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 1.05), ncols=3, fontsize=fontSize)\n",
    "plt.subplots_adjust(wspace=0.0, hspace=0.0)  # Remove horizontal spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('output/GB_vs_lr.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/NB_initial_data.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[(df['Features'] == 'n')]\n",
    "df2 = df[(df['Features'] == 'a, n')]\n",
    "df3 = df[(df['Features'] == 'a, e, n')]\n",
    "df1['Train R'] = df1['Train R'].astype(int)\n",
    "df2['Train R'] = df2['Train R'].astype(int)\n",
    "df3['Train R'] = df3['Train R'].astype(int)\n",
    "\n",
    "df1 = df1.sort_values(by='Train R', ascending=True)\n",
    "df2 = df2.sort_values(by='Train R', ascending=True)\n",
    "df3 = df3.sort_values(by='Train R', ascending=True)\n",
    "df1.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontSize = 18\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 6), sharey=True, sharex=True)\n",
    "\n",
    "i=0\n",
    "dfs = [df1, df2, df3]\n",
    "labels = ['Features: $n$', 'Features: $a$, $n$', 'Features: $a$, $e$, $n$']\n",
    "for ax in axs:\n",
    "    ax.plot(dfs[i]['Train R'], dfs[i]['Rec.'], label='Recall', c='#1f77b4', marker='o', linestyle='-', linewidth=1, markersize=2)\n",
    "    ax.plot(dfs[i]['Train R'], dfs[i]['Prec.'], label='Precision', c='#7f7f7f', marker='^', linestyle='-', linewidth=1, markersize=2)\n",
    "    ax.plot(dfs[i]['Train R'], dfs[i]['F1'], label='$F_1$ score', c='#d62728', marker='s', linestyle='-', linewidth=1, markersize=2)\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.3)\n",
    "    ax.set_ylabel('Metrics', fontsize=fontSize)\n",
    "    if i==2:\n",
    "        ax.set_xlabel('n, the number of resonant asteroids in the training set', fontsize=fontSize)\n",
    "    ax.set_title(f\"{labels[i]}\", fontsize=fontSize)\n",
    "    ax.set_ylim(0.7, 1)\n",
    "    ax.set_xlim(5, 100)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=fontSize)\n",
    "    ax.legend().remove()\n",
    "    i+=1\n",
    "\n",
    "plt.setp(axs, xticks=range(10, 100, 10), yticks=[0.7, 0.8, 0.9, 1.0])\n",
    "plt.subplots_adjust(wspace=0.0)  # Remove horizontal spacing between subplots\n",
    "\n",
    "fig.suptitle('Metrics vs the size of the training set', fontsize=fontSize+5, y=1.1)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 1.05), ncols=3, fontsize=fontSize)\n",
    "plt.subplots_adjust(wspace=0.0, hspace=0.0)  # Remove horizontal spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('output/NB_initial_data.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in dfs:\n",
    "    print(elem.sort_values(by='F1', ascending=False).head(10)[['Train R', 'Rec.', 'Prec.', 'F1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/GB_grid_vs_d100.csv')\n",
    "df['Max_depth'] = df['Max_depth'].fillna(0).astype(int)\n",
    "df.sort_values(by='F1 score', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [\n",
    "    df[(df['Features'] == 'a, e') & (df['Min_samples_split'] == 9) & (df['Loss'] == 'exponential') & (df['Max_features'] == 'sqrt') & (df['N_estimators'] == 95)].sort_values(by='Max_depth'),\n",
    "    df[(df['Features'] == 'a, sinI') & (df['Min_samples_split'] == 3) & (df['Loss'] == 'exponential') & (df['Max_features'] == 'sqrt') & (df['N_estimators'] == 55)].sort_values(by='Max_depth'),\n",
    "    df[(df['Features'] == 'a, e, n') & (df['Min_samples_split'] == 5) & (df['Loss'] == 'exponential') & (df['Max_features'] == 'sqrt') & (df['N_estimators'] == 95)].sort_values(by='Max_depth'),\n",
    "]\n",
    "# 0,1,\"a, e\",1.000,0.956,0.970,0.962,0.1,exponential,5,sqrt,9,95\n",
    "# 1,2,\"a, sinI\",1.000,0.962,0.962,0.962,0.1,exponential,5,sqrt,3,55\n",
    "# 7,8,\"a, e, n\",1.000,0.963,0.963,0.961,0.1,exponential,5,sqrt,5,95\n",
    "\n",
    "fontSize=18\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 6), sharey=False, sharex=True)\n",
    "\n",
    "i=0\n",
    "labels = ['Features: $a$, $e$; $n=95$; $s=9$', 'Features: $a$, $\\sin{I}$; $n=55$; $s=3$', 'Features: $a$, $e$, $n$; $n=55$; $s=5$', 'Features: $a$, $e$, $n$; $n=95$; $d=0$']\n",
    "for ax in axs:\n",
    "    ax.plot(dfs[i]['Max_depth'], dfs[i]['Recall'], label='Recall', c='#1f77b4', marker='o', linestyle='-', linewidth=1, markersize=2)\n",
    "    ax.plot(dfs[i]['Max_depth'], dfs[i]['Precision'], label='Precision', c='#7f7f7f', marker='^', linestyle='-', linewidth=1, markersize=2)\n",
    "    ax.plot(dfs[i]['Max_depth'], dfs[i]['F1 score'], label='$F_1$ score', c='#d62728', marker='s', linestyle='-', linewidth=1, markersize=2)\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.3)\n",
    "    ax.set_ylabel('Metrics', fontsize=fontSize)\n",
    "    if i==2:\n",
    "        ax.set_xlabel('d, the maximum depth', fontsize=fontSize)\n",
    "    ax.set_title(f\"{labels[i]}\", fontsize=fontSize)\n",
    "    ax.set_ylim(0.9, 1.00)\n",
    "    ax.set_xlim(1, 100)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=fontSize)\n",
    "    ax.legend().remove()\n",
    "    i+=1\n",
    "\n",
    "plt.setp(axs, xticks=range(0, 101, 10), yticks=[0.90, 0.95, 1.00])\n",
    "plt.subplots_adjust(wspace=0.0)  # Remove horizontal spacing between subplots\n",
    "\n",
    "fig.suptitle('Metrics vs the maximum depth', fontsize=fontSize+5, y=1.1)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 1.05), ncols=3, fontsize=fontSize)\n",
    "plt.subplots_adjust(wspace=0.0, hspace=0.0)  # Remove horizontal spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('output/GB_vs_d100.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[0].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/GB_final_ae.csv')\n",
    "df2 = pd.read_csv('data/GB_final_ai.csv')\n",
    "df['Max_depth'] = df['Max_depth'].fillna(0).astype(int)\n",
    "df2['Max_depth'] = df2['Max_depth'].fillna(0).astype(int)\n",
    "df.sort_values(by='F1 score', ascending=False).head(20)\n",
    "df2.sort_values(by='F1 score', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [\n",
    "    df[(df['Features'] == 'a, e') & (df['Min_samples_split'] == 9) & (df['Loss'] == 'exponential') & (df['Max_features'] == 'sqrt') & (df['Max_depth'] == 5)].sort_values(by='N_estimators'),\n",
    "    df2[(df2['Features'] == 'a, sinI') & (df2['Min_samples_split'] == 3) & (df2['Loss'] == 'exponential') & (df2['Max_features'] == 'sqrt') & (df2['Max_depth'] == 5)].sort_values(by='N_estimators'),\n",
    "]\n",
    "\n",
    "fontSize=18\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 4), sharey=False, sharex=True)\n",
    "\n",
    "i=0\n",
    "labels = ['Features: $a$, $e$; $d=5$; $s=9$', 'Features: $a$, $\\sin{I}$; $d=5$; $s=3$', 'Features: $a$, $e$, $n$; $n=55$; $s=5$', 'Features: $a$, $e$, $n$; $n=95$; $d=0$']\n",
    "for ax in axs:\n",
    "    ax.plot(dfs[i]['N_estimators'], dfs[i]['Recall'], label='Recall', c='#1f77b4', marker='o', linestyle='-', linewidth=1, markersize=2)\n",
    "    ax.plot(dfs[i]['N_estimators'], dfs[i]['Precision'], label='Precision', c='#7f7f7f', marker='^', linestyle='-', linewidth=1, markersize=2)\n",
    "    ax.plot(dfs[i]['N_estimators'], dfs[i]['F1 score'], label='$F_1$ score', c='#d62728', marker='s', linestyle='-', linewidth=1, markersize=2)\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.3)\n",
    "    ax.set_ylabel('Metrics', fontsize=fontSize)\n",
    "    if i==1:\n",
    "        ax.set_xlabel('n, the number of estimators', fontsize=fontSize)\n",
    "    ax.set_title(f\"{labels[i]}\", fontsize=fontSize)\n",
    "    ax.set_ylim(0.0, 1.00)\n",
    "    ax.set_xlim(1, 100)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=fontSize)\n",
    "    ax.legend().remove()\n",
    "    i+=1\n",
    "\n",
    "plt.setp(axs, xticks=range(0, 101, 10), yticks=[0.0, 0.50, 1.00])\n",
    "plt.subplots_adjust(wspace=0.0)  # Remove horizontal spacing between subplots\n",
    "\n",
    "fig.suptitle('Metrics vs the number of estimators', fontsize=fontSize+5, y=1.1)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 1.05), ncols=3, fontsize=fontSize)\n",
    "plt.subplots_adjust(wspace=0.0, hspace=0.0)  # Remove horizontal spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('output/GB_vs_n_est.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/GB_initial_data.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[(df['Features'] == 'a, e') & (df['Meth. & Params'] == 'GB1')].sort_values(by='Train R')\n",
    "# df2 = df[(df['Features'] == 'a, sinI') & (df['Meth. & Params'] == 'GB2')].sort_values(by='Train R')\n",
    "\n",
    "fontSize = 24\n",
    "\n",
    "x = df2['Train R']\n",
    "y1 = df2['Rec.']\n",
    "y2 = df2['Prec.']\n",
    "y3 = df2['F1']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(10))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.05))\n",
    "\n",
    "plt.plot(x, y1, c='#1f77b4', label='Recall', marker='o', linestyle='-', linewidth=1, markersize=2)\n",
    "plt.plot(x, y2, c='#7f7f7f', label='Precision', marker='^', linestyle='-', linewidth=1, markersize=2)\n",
    "plt.plot(x, y3, c='#d62728', label='$F_1$ score', marker='s', linestyle='-', linewidth=1, markersize=2)\n",
    "\n",
    "plt.xticks(range(0, 101, 20), fontsize=fontSize)\n",
    "plt.yticks([i/10 for i in range(11)], fontsize=fontSize)\n",
    "\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.3)\n",
    "\n",
    "plt.xlabel('n, The number of resonant asteroids in the training set', fontsize=fontSize)\n",
    "plt.ylabel('Metrics', fontsize=fontSize)\n",
    "# plt.title('Metrics vs n', fontsize=fontSize)\n",
    "plt.legend(fontsize=fontSize-4)\n",
    "\n",
    "plt.ylim(0.65, 1.01)\n",
    "plt.xlim(2, 100)\n",
    "\n",
    "plt.savefig('output/GB_initial_data.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Ada_grid_vs_n_est.csv')\n",
    "\n",
    "best_f1_scores = df.groupby('Features')['F1 score'].idxmax()\n",
    "best_df = df.loc[best_f1_scores, ['Features', 'N_estimators', 'Accuracy', 'Precision', 'Recall', 'F1 score']]\n",
    "best_df = best_df.sort_values(by='F1 score', ascending=False)\n",
    "best_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_table = best_df.to_latex(index=False)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [\n",
    "    df[(df['Features'] == 'a, e, sinI')].sort_values(by='N_estimators'),\n",
    "    df[(df['Features'] == 'a, n')].sort_values(by='N_estimators'),\n",
    "]\n",
    "\n",
    "fontSize=18\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 4), sharey=False, sharex=True)\n",
    "\n",
    "i=0\n",
    "labels = ['Features: $a$, $e$, $\\sin{I}$', 'Features: $a$, $n$']\n",
    "for ax in axs:\n",
    "    ax.plot(dfs[i]['N_estimators'], dfs[i]['Recall'], label='Recall', c='#1f77b4', marker='o', linestyle='-', linewidth=1, markersize=2)\n",
    "    ax.plot(dfs[i]['N_estimators'], dfs[i]['Precision'], label='Precision', c='#7f7f7f', marker='^', linestyle='-', linewidth=1, markersize=2)\n",
    "    ax.plot(dfs[i]['N_estimators'], dfs[i]['F1 score'], label='$F_1$ score', c='#d62728', marker='s', linestyle='-', linewidth=1, markersize=2)\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.3)\n",
    "    ax.set_ylabel('Metrics', fontsize=fontSize)\n",
    "    if i==1:\n",
    "        ax.set_xlabel('n, the number of estimators', fontsize=fontSize)\n",
    "    ax.set_title(f\"{labels[i]}\", fontsize=fontSize)\n",
    "    ax.set_ylim(0.9, 1.00)\n",
    "    ax.set_xlim(100, 2000)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=fontSize)\n",
    "    ax.legend().remove()\n",
    "    i+=1\n",
    "\n",
    "plt.setp(axs, xticks=range(100, 2001, 200), yticks=[0.90, 0.950, 1.00])\n",
    "plt.subplots_adjust(wspace=0.0)  # Remove horizontal spacing between subplots\n",
    "\n",
    "fig.suptitle('Metrics vs the number of estimators', fontsize=fontSize+5, y=1.1)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 1.05), ncols=3, fontsize=fontSize)\n",
    "plt.subplots_adjust(wspace=0.0, hspace=0.0)  # Remove horizontal spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('output/Ada_vs_n_est.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Ada_initial_data.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = df[(df['Features'] == 'a, e') & (df['Meth. & Params'] == 'GB1')].sort_values(by='Train R')\n",
    "df2 = df.sort_values(by='Train R')\n",
    "# df2 = df[(df['Features'] == 'a, sinI') & (df['Meth. & Params'] == 'GB2')].sort_values(by='Train R')\n",
    "\n",
    "fontSize = 20\n",
    "\n",
    "x = df2['Train R']\n",
    "y1 = df2['Rec.']\n",
    "y2 = df2['Prec.']\n",
    "y3 = df2['F1']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(10))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.05))\n",
    "\n",
    "plt.plot(x, y1, c='#1f77b4', label='Recall', marker='o', linestyle='-', linewidth=1, markersize=2)\n",
    "plt.plot(x, y2, c='#7f7f7f', label='Precision', marker='^', linestyle='-', linewidth=1, markersize=2)\n",
    "plt.plot(x, y3, c='#d62728', label='$F_1$ score', marker='s', linestyle='-', linewidth=1, markersize=2)\n",
    "\n",
    "plt.xticks(range(0, 101, 20), fontsize=fontSize)\n",
    "plt.yticks([i/10 for i in range(11)], fontsize=fontSize)\n",
    "\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.3)\n",
    "\n",
    "plt.xlabel('n, The number of resonant asteroids in the training set', fontsize=fontSize)\n",
    "plt.ylabel('Metrics', fontsize=fontSize)\n",
    "# plt.title('Metrics vs n', fontsize=fontSize)\n",
    "plt.legend(fontsize=fontSize-4)\n",
    "\n",
    "plt.ylim(0.65, 1.01)\n",
    "plt.xlim(2, 100)\n",
    "\n",
    "plt.savefig('output/Ada_initial_data.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/RF_grid.csv')\n",
    "df['Max_depth'] = df['Max_depth'].fillna('None').astype(str)\n",
    "df['Class_weight'] = df['Class_weight'].fillna('None').astype(str)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_table = df[['Features', 'Max_depth', 'N_estimators', 'Class_weight', 'Accuracy', 'Precision', 'Recall', 'F1 score']].sort_values(by='F1 score', ascending=False).head(10).to_latex(index=False)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('data/RF_grid_aen_vs_n_est.csv')\n",
    "df2 = pd.read_csv('data/RF_grid_aein_vs_n_est.csv')\n",
    "for df in [df1, df2]:\n",
    "    df['Max_depth'] = df['Max_depth'].fillna(0).astype(int)\n",
    "    df['Class_weight'] = df['Class_weight'].fillna('None').astype(str)\n",
    "df1[(df1['Features'] == 'a, e, n') & (df1['Max_depth'] == 0) & (df1['Class_weight'] == 'None')].sort_values(by='N_estimators').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [\n",
    "    df1[(df1['Features'] == 'a, e, n') & (df1['Max_depth'] == 0)].sort_values(by='N_estimators'),\n",
    "    df2[(df2['Max_depth'] == 0)].sort_values(by='N_estimators'),\n",
    "    # df1[(df1['Features'] == 'a, e, n') & (df1['Max_depth'] == 0) & (df1['Class_weight'] == 'balanced')].sort_values(by='N_estimators'),\n",
    "    # df[(df['Features'] == 'a, e, n, sinI')].sort_values(by='N_estimators'),\n",
    "]\n",
    "\n",
    "fontSize=18\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 4), sharey=False, sharex=True)\n",
    "\n",
    "i=0\n",
    "labels = ['Features: $a$, $e$, $n$', 'Features: $a$, $e$, $n$, $\\sin{I}$']\n",
    "for ax in axs:\n",
    "    # ax.plot(dfs[i]['N_estimators'], dfs[i]['Recall'], label='Recall', c='#1f77b4', marker='o', linestyle='-', linewidth=1, markersize=2)\n",
    "    # ax.plot(dfs[i]['N_estimators'], dfs[i]['Precision'], label='Precision', c='#7f7f7f', marker='^', linestyle='-', linewidth=1, markersize=2)\n",
    "    ax.plot(dfs[i][(dfs[i]['Class_weight'] == 'None')]['N_estimators'], dfs[i][(dfs[i]['Class_weight'] == 'None')]['F1 score'], label='None', c='#d62728', marker='s', linestyle='-', linewidth=1, markersize=2)\n",
    "    ax.plot(dfs[i][(dfs[i]['Class_weight'] == 'balanced')]['N_estimators'], dfs[i][(dfs[i]['Class_weight'] == 'balanced')]['F1 score'], label='Balanced', c='#7f7f7f', marker='^', linestyle='-', linewidth=1, markersize=2)\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.3)\n",
    "    ax.set_ylabel('$F_1$ score', fontsize=fontSize)\n",
    "    if i==1:\n",
    "        ax.set_xlabel('n, the number of estimators', fontsize=fontSize)\n",
    "    ax.set_title(f\"{labels[i]}\", fontsize=fontSize)\n",
    "    ax.set_ylim(0.93, 0.97)\n",
    "    ax.set_xlim(1, 100)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=fontSize)\n",
    "    ax.legend().remove()\n",
    "    i+=1\n",
    "\n",
    "plt.setp(axs, xticks=range(0, 100, 10), yticks=[0.93, 0.950, 0.97])\n",
    "plt.subplots_adjust(wspace=0.0)  # Remove horizontal spacing between subplots\n",
    "\n",
    "fig.suptitle('$F_1$ score vs the class weights and the number of estimators', fontsize=fontSize+2, y=1.1)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 1.05), ncols=3, fontsize=fontSize)\n",
    "plt.subplots_adjust(wspace=0.0, hspace=0.0)  # Remove horizontal spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('output/RF_vs_n_est_weights.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "dfs[0].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/RF_initial_data.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = df[(df['Features'] == 'a, e') & (df['Meth. & Params'] == 'GB1')].sort_values(by='Train R')\n",
    "df2 = df.sort_values(by='Train R')\n",
    "# df2 = df[(df['Features'] == 'a, sinI') & (df['Meth. & Params'] == 'GB2')].sort_values(by='Train R')\n",
    "\n",
    "fontSize = 20\n",
    "\n",
    "x = df2['Train R']\n",
    "y1 = df2['Rec.']\n",
    "y2 = df2['Prec.']\n",
    "y3 = df2['F1']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(10))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.05))\n",
    "\n",
    "plt.plot(x, y1, c='#1f77b4', label='Recall', marker='o', linestyle='-', linewidth=1, markersize=2)\n",
    "plt.plot(x, y2, c='#7f7f7f', label='Precision', marker='^', linestyle='-', linewidth=1, markersize=2)\n",
    "plt.plot(x, y3, c='#d62728', label='$F_1$ score', marker='s', linestyle='-', linewidth=1, markersize=2)\n",
    "\n",
    "plt.xticks(range(0, 101, 20), fontsize=fontSize)\n",
    "plt.yticks([i/10 for i in range(11)], fontsize=fontSize)\n",
    "\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.3)\n",
    "\n",
    "plt.xlabel('n, The number of resonant asteroids in the training set', fontsize=fontSize)\n",
    "plt.ylabel('Metrics', fontsize=fontSize)\n",
    "# plt.title('Metrics vs n', fontsize=fontSize)\n",
    "plt.legend(fontsize=fontSize-4)\n",
    "\n",
    "plt.ylim(0.65, 1.01)\n",
    "plt.xlim(2, 100)\n",
    "\n",
    "plt.savefig('output/RF_initial_data.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/BRF_grid_sm.csv')\n",
    "df['Max_depth'] = df['Max_depth'].fillna(0).astype(int)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_table = df[['Features', 'Max_depth', 'Min_samples_split', 'N_estimators', 'Accuracy', 'Precision', 'Recall', 'F1 score']].head(10).to_latex(index=False)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/final.csv')\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_table = df[['Train R', 'Meth. & Params', 'Features', 'TP', 'FP', 'TN', 'FN', 'Acc.', 'Prec.', 'Rec.', 'F1']].head(10).to_latex(index=False)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
